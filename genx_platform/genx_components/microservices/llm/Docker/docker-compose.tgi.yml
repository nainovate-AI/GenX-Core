# genx_platform/genx_components/microservices/llm/docker-compose.tgi.yml
version: '3.8'

services:
  tgi-server:
    image: ghcr.io/huggingface/text-generation-inference:latest
    container_name: tgi-server
    ports:
      - "8080:80"
    volumes:
      - ${HF_CACHE:-~/.cache/huggingface}:/data
    environment:
      - MODEL_ID=${TGI_MODEL_ID:-mistralai/Mistral-7B-Instruct-v0.2}
      - MAX_INPUT_LENGTH=${TGI_MAX_INPUT_LENGTH:-4096}
      - MAX_TOTAL_TOKENS=${TGI_MAX_TOTAL_TOKENS:-8192}
      - QUANTIZE=${TGI_QUANTIZE:-}
      - NUM_SHARD=${TGI_NUM_SHARD:-1}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    shm_size: 1g
    restart: unless-stopped