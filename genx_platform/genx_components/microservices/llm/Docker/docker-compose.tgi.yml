# genx_platform/genx_components/microservices/llm/docker-compose.tgi.yml
version: '3.8'

services:
  tgi-server:
    image: ghcr.io/huggingface/text-generation-inference:latest
    container_name: tgi-server
    ports:
      - "8080:80"
    volumes:
      - ${HF_CACHE:-~/.cache/huggingface}:/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    shm_size: 1g
    restart: unless-stopped